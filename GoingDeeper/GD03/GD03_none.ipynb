{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "335c9884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f783687f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca9fd70",
   "metadata": {},
   "source": [
    "## 데이터 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9b385a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'stanford_dogs',\n",
    "    split=['train', 'test'],\n",
    "    as_supervised=True,\n",
    "    shuffle_files=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c7d306",
   "metadata": {},
   "source": [
    "## 주요 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e04fa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_resize_img(image, label):\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    return tf.cast(image, tf.float32) / 255., label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bf964fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(image, label):\n",
    "    label = tf.one_hot(label, num_classes)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8715a946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for mixup\n",
    "def mixup_2_images(image_a, image_b, label_a, label_b):\n",
    "    ratio = tf.random.uniform([], 0, 1)\n",
    "    \n",
    "    if len(label_a.shape)==0:\n",
    "        label_a = tf.one_hot(label_a, num_classes)\n",
    "    if len(label_b.shape)==0:\n",
    "        label_b = tf.one_hot(label_b, num_classes)\n",
    "    mixed_image= (1-ratio)*image_a + ratio*image_b\n",
    "    mixed_label = (1-ratio)*label_a + ratio*label_b\n",
    "    \n",
    "    return mixed_image, mixed_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a242be0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(image, label, prob=1.0, batch_size=16, img_size=224, num_classes=120):\n",
    "    mixed_imgs = []\n",
    "    mixed_labels = []\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        image_a = image[i]\n",
    "        label_a = label[i]\n",
    "        j = tf.cast(tf.random.uniform([],0,batch_size), tf.int32)\n",
    "        image_b = image[j]\n",
    "        label_b = label[j]\n",
    "        mixed_img, mixed_label = mixup_2_images(image_a, image_b, label_a, label_b)\n",
    "        mixed_imgs.append(mixed_img)\n",
    "        mixed_labels.append(mixed_label)\n",
    "\n",
    "    mixed_imgs = tf.reshape(tf.stack(mixed_imgs), (batch_size, img_size, img_size, 3))\n",
    "    mixed_labels = tf.reshape(tf.stack(mixed_labels), (batch_size, num_classes))\n",
    "    return mixed_imgs, mixed_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fa5830b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_normalize_on_dataset(ds, is_test=False, batch_size=16, with_mixup=False):\n",
    "    ds = ds.map(\n",
    "        normalize_and_resize_img,\n",
    "        num_parallel_calls=2\n",
    "    )\n",
    "    ds = ds.map(\n",
    "        onehot,\n",
    "        num_parallel_calls=2\n",
    "    )\n",
    "    ds = ds.batch(batch_size)\n",
    "    if not is_test and with_mixup:\n",
    "        ds_mixup = ds.map(\n",
    "            mixup,\n",
    "            num_parallel_calls=2\n",
    "        )\n",
    "    if not is_test:\n",
    "        ds = ds.repeat()\n",
    "        ds = ds.shuffle(200)\n",
    "    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14a70151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def history_conv(history):\n",
    "    \n",
    "    return_history = {'loss' : list(history['loss'].values()),\n",
    "                      'accuracy' : list(history['accuracy'].values()),\n",
    "                      'val_loss' : list(history['val_loss'].values()),\n",
    "                      'val_accuracy' : list(history['val_accuracy'].values())}\n",
    "    \n",
    "    return return_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cbab92",
   "metadata": {},
   "source": [
    "## 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8311909",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fe5b0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = ds_info.features[\"label\"].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffea62fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_mixup = apply_normalize_on_dataset(ds_train, batch_size=BATCH_SIZE, with_mixup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e4dd3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test_all = apply_normalize_on_dataset(ds_test, batch_size=BATCH_SIZE, is_test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c2b7d2",
   "metadata": {},
   "source": [
    "## 모델 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8aa03820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_classes):\n",
    "    base_model = keras.applications.resnet.ResNet50(\n",
    "        include_top=False,\n",
    "        weights=None,\n",
    "        input_shape=(224,224,3),\n",
    "        pooling='avg')\n",
    "    \n",
    "    output = base_model.output\n",
    "    \n",
    "    output = keras.layers.Dense(num_classes, activation='softmax', use_bias=False)(output)\n",
    "    model = keras.Model(inputs=base_model.input, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66428691",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixup_model = build_model(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44cf19bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 120)          245760      avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 23,833,472\n",
      "Trainable params: 23,780,352\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mixup_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7b75ff",
   "metadata": {},
   "source": [
    "## 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf9f8500",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0084b720",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_mixup = tf.keras.callbacks.ModelCheckpoint(os.getenv('HOME')+\"/aiffel/model_weight/mixup_model_None.keras\", monitor='val_loss', verbose=1, save_best_only=True, mode='min', save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7efe293d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "750/750 [==============================] - 212s 201ms/step - loss: 5.1066 - accuracy: 0.0124 - val_loss: 5.0721 - val_accuracy: 0.0194\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 5.07212, saving model to /aiffel/aiffel/model_weight/mixup_model_None.keras\n",
      "Epoch 2/50\n",
      "750/750 [==============================] - 152s 203ms/step - loss: 4.6556 - accuracy: 0.0248 - val_loss: 4.9397 - val_accuracy: 0.0285\n",
      "\n",
      "Epoch 00002: val_loss improved from 5.07212 to 4.93969, saving model to /aiffel/aiffel/model_weight/mixup_model_None.keras\n",
      "Epoch 3/50\n",
      "750/750 [==============================] - 153s 204ms/step - loss: 4.4349 - accuracy: 0.0412 - val_loss: 4.5020 - val_accuracy: 0.0532\n",
      "\n",
      "Epoch 00003: val_loss improved from 4.93969 to 4.50203, saving model to /aiffel/aiffel/model_weight/mixup_model_None.keras\n",
      "Epoch 4/50\n",
      "750/750 [==============================] - 153s 203ms/step - loss: 4.2290 - accuracy: 0.0570 - val_loss: 4.5332 - val_accuracy: 0.0440\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 4.50203\n",
      "Epoch 5/50\n",
      "750/750 [==============================] - 153s 203ms/step - loss: 4.0462 - accuracy: 0.0782 - val_loss: 4.7788 - val_accuracy: 0.0498\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 4.50203\n",
      "Epoch 6/50\n",
      "750/750 [==============================] - 153s 203ms/step - loss: 3.8556 - accuracy: 0.1036 - val_loss: 4.6773 - val_accuracy: 0.0559\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 4.50203\n",
      "Epoch 7/50\n",
      "750/750 [==============================] - 153s 203ms/step - loss: 3.6757 - accuracy: 0.1206 - val_loss: 4.5134 - val_accuracy: 0.0704\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 4.50203\n",
      "Epoch 8/50\n",
      "750/750 [==============================] - 152s 203ms/step - loss: 3.4457 - accuracy: 0.1598 - val_loss: 4.8202 - val_accuracy: 0.0624\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 4.50203\n",
      "Epoch 9/50\n",
      "750/750 [==============================] - 152s 203ms/step - loss: 3.2266 - accuracy: 0.1963 - val_loss: 4.9553 - val_accuracy: 0.0721\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 4.50203\n",
      "Epoch 10/50\n",
      "750/750 [==============================] - 152s 203ms/step - loss: 2.9510 - accuracy: 0.2475 - val_loss: 5.2213 - val_accuracy: 0.0588\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 4.50203\n",
      "Epoch 11/50\n",
      "750/750 [==============================] - 152s 203ms/step - loss: 2.6503 - accuracy: 0.3064 - val_loss: 5.3141 - val_accuracy: 0.0717\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 4.50203\n",
      "Epoch 12/50\n",
      "750/750 [==============================] - 152s 203ms/step - loss: 2.2834 - accuracy: 0.3873 - val_loss: 5.4601 - val_accuracy: 0.0675\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 4.50203\n",
      "Epoch 13/50\n",
      "750/750 [==============================] - 168s 224ms/step - loss: 1.9122 - accuracy: 0.4754 - val_loss: 6.0316 - val_accuracy: 0.0661\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 4.50203\n",
      "Epoch 14/50\n",
      "750/750 [==============================] - 153s 203ms/step - loss: 1.4833 - accuracy: 0.5858 - val_loss: 6.1169 - val_accuracy: 0.0815\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 4.50203\n",
      "Epoch 15/50\n",
      "750/750 [==============================] - 152s 203ms/step - loss: 1.0489 - accuracy: 0.7084 - val_loss: 6.1650 - val_accuracy: 0.0694\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 4.50203\n",
      "Epoch 16/50\n",
      "750/750 [==============================] - 152s 203ms/step - loss: 0.6598 - accuracy: 0.8289 - val_loss: 6.6986 - val_accuracy: 0.0686\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 4.50203\n",
      "Epoch 17/50\n",
      "750/750 [==============================] - 152s 203ms/step - loss: 0.3723 - accuracy: 0.9157 - val_loss: 7.1878 - val_accuracy: 0.0719\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 4.50203\n",
      "Epoch 18/50\n",
      "750/750 [==============================] - 152s 203ms/step - loss: 0.1900 - accuracy: 0.9632 - val_loss: 6.0459 - val_accuracy: 0.0922\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 4.50203\n",
      "Epoch 19/50\n",
      "750/750 [==============================] - 152s 203ms/step - loss: 0.0926 - accuracy: 0.9852 - val_loss: 6.2337 - val_accuracy: 0.0934\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 4.50203\n",
      "Epoch 20/50\n",
      "750/750 [==============================] - 152s 203ms/step - loss: 0.0522 - accuracy: 0.9930 - val_loss: 6.0364 - val_accuracy: 0.0975\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 4.50203\n",
      "Epoch 21/50\n",
      "750/750 [==============================] - 153s 203ms/step - loss: 0.0605 - accuracy: 0.9884 - val_loss: 7.4622 - val_accuracy: 0.0688\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 4.50203\n",
      "Epoch 22/50\n",
      "750/750 [==============================] - 152s 203ms/step - loss: 1.1975 - accuracy: 0.6674 - val_loss: 6.7599 - val_accuracy: 0.0675\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 4.50203\n",
      "Epoch 23/50\n",
      "750/750 [==============================] - 152s 203ms/step - loss: 0.4600 - accuracy: 0.8764 - val_loss: 6.2617 - val_accuracy: 0.0960\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 4.50203\n",
      "Epoch 24/50\n",
      "750/750 [==============================] - 152s 203ms/step - loss: 0.0973 - accuracy: 0.9830 - val_loss: 6.0310 - val_accuracy: 0.1052\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 4.50203\n",
      "Epoch 25/50\n",
      "750/750 [==============================] - 152s 203ms/step - loss: 0.0272 - accuracy: 0.9965 - val_loss: 6.1382 - val_accuracy: 0.1072\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 4.50203\n",
      "Epoch 26/50\n",
      "750/750 [==============================] - 152s 203ms/step - loss: 0.0210 - accuracy: 0.9973 - val_loss: 6.0458 - val_accuracy: 0.1049\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 4.50203\n",
      "Epoch 27/50\n",
      "750/750 [==============================] - 152s 203ms/step - loss: 0.0157 - accuracy: 0.9980 - val_loss: 6.0806 - val_accuracy: 0.1041\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 4.50203\n",
      "Epoch 28/50\n",
      "750/750 [==============================] - 152s 203ms/step - loss: 0.0150 - accuracy: 0.9975 - val_loss: 6.0774 - val_accuracy: 0.1034\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 4.50203\n",
      "Epoch 29/50\n",
      "750/750 [==============================] - 152s 203ms/step - loss: 0.0132 - accuracy: 0.9983 - val_loss: 6.1584 - val_accuracy: 0.0996\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 4.50203\n",
      "Epoch 30/50\n",
      "750/750 [==============================] - 152s 203ms/step - loss: 0.0108 - accuracy: 0.9987 - val_loss: 6.0665 - val_accuracy: 0.1070\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 4.50203\n",
      "Epoch 31/50\n",
      "750/750 [==============================] - 152s 203ms/step - loss: 0.0138 - accuracy: 0.9978 - val_loss: 6.1210 - val_accuracy: 0.1045\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 4.50203\n",
      "Epoch 32/50\n",
      "750/750 [==============================] - 152s 203ms/step - loss: 0.0108 - accuracy: 0.9986 - val_loss: 6.0770 - val_accuracy: 0.1110\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 4.50203\n",
      "Epoch 33/50\n",
      "750/750 [==============================] - 152s 203ms/step - loss: 0.0097 - accuracy: 0.9990 - val_loss: 6.1682 - val_accuracy: 0.1023\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 4.50203\n",
      "Epoch 34/50\n",
      "750/750 [==============================] - 152s 203ms/step - loss: 0.0054 - accuracy: 0.9994 - val_loss: 6.0378 - val_accuracy: 0.1108\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 4.50203\n",
      "Epoch 35/50\n",
      "750/750 [==============================] - 152s 203ms/step - loss: 0.0053 - accuracy: 0.9994 - val_loss: 6.1306 - val_accuracy: 0.1114\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 4.50203\n",
      "Epoch 36/50\n",
      "750/750 [==============================] - 152s 203ms/step - loss: 0.0072 - accuracy: 0.9988 - val_loss: 6.3154 - val_accuracy: 0.1049\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 4.50203\n",
      "Epoch 37/50\n",
      "750/750 [==============================] - 152s 203ms/step - loss: 0.0078 - accuracy: 0.9992 - val_loss: 6.1319 - val_accuracy: 0.1076\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 4.50203\n",
      "Epoch 38/50\n",
      "750/750 [==============================] - 152s 203ms/step - loss: 0.0068 - accuracy: 0.9990 - val_loss: 6.2088 - val_accuracy: 0.1080\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 4.50203\n",
      "Epoch 39/50\n",
      "750/750 [==============================] - 152s 203ms/step - loss: 0.0064 - accuracy: 0.9993 - val_loss: 6.7987 - val_accuracy: 0.0928\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 4.50203\n",
      "Epoch 40/50\n",
      "750/750 [==============================] - 152s 203ms/step - loss: 0.0066 - accuracy: 0.9989 - val_loss: 6.3341 - val_accuracy: 0.1038\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 4.50203\n",
      "Epoch 41/50\n",
      "750/750 [==============================] - 152s 203ms/step - loss: 0.0067 - accuracy: 0.9989 - val_loss: 7.0910 - val_accuracy: 0.0885\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 4.50203\n",
      "Epoch 42/50\n",
      "750/750 [==============================] - 153s 204ms/step - loss: 0.0107 - accuracy: 0.9984 - val_loss: 6.2910 - val_accuracy: 0.0956\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 4.50203\n",
      "Epoch 43/50\n",
      "750/750 [==============================] - 153s 204ms/step - loss: 0.0083 - accuracy: 0.9989 - val_loss: 6.2988 - val_accuracy: 0.1074\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 4.50203\n",
      "Epoch 44/50\n",
      "750/750 [==============================] - 152s 203ms/step - loss: 0.0059 - accuracy: 0.9990 - val_loss: 6.2703 - val_accuracy: 0.1083\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 4.50203\n",
      "Epoch 45/50\n",
      "750/750 [==============================] - 152s 203ms/step - loss: 0.0059 - accuracy: 0.9992 - val_loss: 6.2655 - val_accuracy: 0.1039\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 4.50203\n",
      "Epoch 46/50\n",
      "750/750 [==============================] - 153s 204ms/step - loss: 0.0108 - accuracy: 0.9983 - val_loss: 7.0970 - val_accuracy: 0.0969\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 4.50203\n",
      "Epoch 47/50\n",
      "750/750 [==============================] - 152s 203ms/step - loss: 0.1163 - accuracy: 0.9732 - val_loss: 7.4696 - val_accuracy: 0.0737\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 4.50203\n",
      "Epoch 48/50\n",
      "750/750 [==============================] - 152s 203ms/step - loss: 0.0459 - accuracy: 0.9917 - val_loss: 6.5764 - val_accuracy: 0.1018\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 4.50203\n",
      "Epoch 49/50\n",
      "750/750 [==============================] - 152s 203ms/step - loss: 0.0109 - accuracy: 0.9987 - val_loss: 6.4233 - val_accuracy: 0.1052\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 4.50203\n",
      "Epoch 50/50\n",
      "750/750 [==============================] - 153s 203ms/step - loss: 0.0083 - accuracy: 0.9991 - val_loss: 6.3445 - val_accuracy: 0.1063\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 4.50203\n"
     ]
    }
   ],
   "source": [
    "mixup_model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "history_resnet50_mixup = mixup_model.fit(\n",
    "    ds_train_mixup,\n",
    "    steps_per_epoch=int(ds_info.splits['train'].num_examples/16),\n",
    "    validation_steps=int(ds_info.splits['test'].num_examples/16),\n",
    "    epochs=EPOCH,\n",
    "    validation_data=ds_test_all,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    "    callbacks=[checkpoint_mixup]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e525a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixup_model.save_weights(os.getenv('HOME')+'/aiffel/model_weight/resnet50_mixup_model_weight_None.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81194af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixup_model.save(os.getenv('HOME')+'/aiffel/model_weight/resnet50_mixup_all_model_None.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df74668d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('history/history_resnet50_mixup_None.json', 'w') as f:\n",
    "    pd.DataFrame(history_resnet50_mixup.history).to_json(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f7ec3f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(history_resnet50_mixup.history['loss'], 'r')\n",
    "plt.plot(history_resnet50_mixup.history['val_loss'], 'b')\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(history_resnet50_mixup.history['accuracy'], 'r')\n",
    "plt.plot(history_resnet50_mixup.history['val_accuracy'], 'b')\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
