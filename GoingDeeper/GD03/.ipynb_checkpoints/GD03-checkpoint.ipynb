{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fa61de44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dee48581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83634f47",
   "metadata": {},
   "source": [
    "## 데이터 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2ec38b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 778.12 MiB (download: 778.12 MiB, generated: Unknown size, total: 778.12 MiB) to /aiffel/tensorflow_datasets/stanford_dogs/0.2.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b3de92af9e48569c20490bc36dd960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd46358e4c84c5c87b7433412036d29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3711d9c6564d4476896d3fbf1b954749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0133df28934a444b938f1fa9dddf8c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15d3894141a74f209b844d76bfa6bbde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/2 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...:   0%|          | 0/12000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling stanford_dogs-train.tfrecord...:   0%|          | 0/12000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...:   0%|          | 0/8580 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling stanford_dogs-test.tfrecord...:   0%|          | 0/8580 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset stanford_dogs downloaded and prepared to /aiffel/tensorflow_datasets/stanford_dogs/0.2.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'stanford_dogs',\n",
    "    split=['train', 'test'],\n",
    "    as_supervised=True,\n",
    "    shuffle_files=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe360f4e",
   "metadata": {},
   "source": [
    "## 주요 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b79ad937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_resize_img(image, label):\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    return tf.cast(image, tf.float32) / 255., label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec2e4f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(image, label):\n",
    "    label = tf.one_hot(label, num_classes)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61cc1930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for mixup\n",
    "def mixup_2_images(image_a, image_b, label_a, label_b):\n",
    "    ratio = tf.random.uniform([], 0, 1)\n",
    "    \n",
    "    if len(label_a.shape)==0:\n",
    "        label_a = tf.one_hot(label_a, num_classes)\n",
    "    if len(label_b.shape)==0:\n",
    "        label_b = tf.one_hot(label_b, num_classes)\n",
    "    mixed_image= (1-ratio)*image_a + ratio*image_b\n",
    "    mixed_label = (1-ratio)*label_a + ratio*label_b\n",
    "    \n",
    "    return mixed_image, mixed_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e180f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(image, label, prob=1.0, batch_size=16, img_size=224, num_classes=120):\n",
    "    mixed_imgs = []\n",
    "    mixed_labels = []\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        image_a = image[i]\n",
    "        label_a = label[i]\n",
    "        j = tf.cast(tf.random.uniform([],0,batch_size), tf.int32)\n",
    "        image_b = image[j]\n",
    "        label_b = label[j]\n",
    "        mixed_img, mixed_label = mixup_2_images(image_a, image_b, label_a, label_b)\n",
    "        mixed_imgs.append(mixed_img)\n",
    "        mixed_labels.append(mixed_label)\n",
    "\n",
    "    mixed_imgs = tf.reshape(tf.stack(mixed_imgs), (batch_size, img_size, img_size, 3))\n",
    "    mixed_labels = tf.reshape(tf.stack(mixed_labels), (batch_size, num_classes))\n",
    "    return mixed_imgs, mixed_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56723720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_normalize_on_dataset(ds, is_test=False, batch_size=16, with_mixup=False):\n",
    "    ds = ds.map(\n",
    "        normalize_and_resize_img,\n",
    "        num_parallel_calls=2\n",
    "    )\n",
    "    ds = ds.map(\n",
    "        onehot,\n",
    "        num_parallel_calls=2\n",
    "    )\n",
    "    ds = ds.batch(batch_size)\n",
    "    if not is_test and with_mixup:\n",
    "        ds_mixup = ds.map(\n",
    "            mixup,\n",
    "            num_parallel_calls=2\n",
    "        )\n",
    "    if not is_test:\n",
    "        ds = ds.repeat()\n",
    "        ds = ds.shuffle(200)\n",
    "    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e999431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def history_conv(history):\n",
    "    \n",
    "    return_history = {'loss' : list(history['loss'].values()),\n",
    "                      'accuracy' : list(history['accuracy'].values()),\n",
    "                      'val_loss' : list(history['val_loss'].values()),\n",
    "                      'val_accuracy' : list(history['val_accuracy'].values())}\n",
    "    \n",
    "    return return_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a8dcf7",
   "metadata": {},
   "source": [
    "## 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6966e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f23ab52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = ds_info.features[\"label\"].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "242acac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_mixup = apply_normalize_on_dataset(ds_train, batch_size=BATCH_SIZE, with_mixup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17ef8ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test_all = apply_normalize_on_dataset(ds_test, batch_size=BATCH_SIZE, is_test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d552bb4d",
   "metadata": {},
   "source": [
    "## 모델 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9749a631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_classes):\n",
    "    base_model = keras.applications.resnet.ResNet50(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=(224,224,3),\n",
    "        pooling='avg')\n",
    "    \n",
    "    output = base_model.output\n",
    "    \n",
    "    output = keras.layers.Dense(num_classes, activation='softmax', use_bias=False)(output)\n",
    "    model = keras.Model(inputs=base_model.input, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d372ea9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixup_model = build_model(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e6d4242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 120)          245760      avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 23,833,472\n",
      "Trainable params: 23,780,352\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mixup_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c2063c",
   "metadata": {},
   "source": [
    "## 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dae9db97",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bbdd7c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_mixup = tf.keras.callbacks.ModelCheckpoint(os.getenv('HOME')+\"/aiffel/model_weight/mixup_model.keras\", monitor='val_loss', verbose=1, save_best_only=True, mode='min', save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32bc85fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "750/750 [==============================] - 166s 209ms/step - loss: 0.7071 - accuracy: 0.8055 - val_loss: 1.1432 - val_accuracy: 0.6628\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.14317, saving model to /aiffel/aiffel/model_weight/mixup_model.keras\n",
      "Epoch 2/50\n",
      "750/750 [==============================] - 155s 206ms/step - loss: 0.2648 - accuracy: 0.9404 - val_loss: 1.0049 - val_accuracy: 0.7045\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.14317 to 1.00495, saving model to /aiffel/aiffel/model_weight/mixup_model.keras\n",
      "Epoch 3/50\n",
      "750/750 [==============================] - 155s 206ms/step - loss: 0.0668 - accuracy: 0.9948 - val_loss: 0.9200 - val_accuracy: 0.7364\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.00495 to 0.92001, saving model to /aiffel/aiffel/model_weight/mixup_model.keras\n",
      "Epoch 4/50\n",
      "750/750 [==============================] - 155s 206ms/step - loss: 0.0262 - accuracy: 0.9988 - val_loss: 0.9088 - val_accuracy: 0.7430\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.92001 to 0.90879, saving model to /aiffel/aiffel/model_weight/mixup_model.keras\n",
      "Epoch 5/50\n",
      "750/750 [==============================] - 155s 206ms/step - loss: 0.0159 - accuracy: 0.9997 - val_loss: 0.9289 - val_accuracy: 0.7400\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.90879\n",
      "Epoch 6/50\n",
      "750/750 [==============================] - 155s 206ms/step - loss: 0.0123 - accuracy: 0.9999 - val_loss: 0.9375 - val_accuracy: 0.7408\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.90879\n",
      "Epoch 7/50\n",
      "750/750 [==============================] - 155s 206ms/step - loss: 0.0098 - accuracy: 0.9997 - val_loss: 0.9731 - val_accuracy: 0.7374\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.90879\n",
      "Epoch 8/50\n",
      "750/750 [==============================] - 155s 206ms/step - loss: 0.0090 - accuracy: 0.9998 - val_loss: 0.9682 - val_accuracy: 0.7414\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.90879\n",
      "Epoch 9/50\n",
      "750/750 [==============================] - 155s 206ms/step - loss: 0.0069 - accuracy: 0.9999 - val_loss: 0.9693 - val_accuracy: 0.7402\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.90879\n",
      "Epoch 10/50\n",
      "750/750 [==============================] - 155s 206ms/step - loss: 0.0064 - accuracy: 0.9998 - val_loss: 0.9837 - val_accuracy: 0.7390\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.90879\n",
      "Epoch 11/50\n",
      "750/750 [==============================] - 154s 206ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.9917 - val_accuracy: 0.7393\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.90879\n",
      "Epoch 12/50\n",
      "750/750 [==============================] - 154s 205ms/step - loss: 0.0050 - accuracy: 0.9998 - val_loss: 0.9945 - val_accuracy: 0.7392\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.90879\n",
      "Epoch 13/50\n",
      "750/750 [==============================] - 154s 205ms/step - loss: 0.0053 - accuracy: 0.9996 - val_loss: 0.9948 - val_accuracy: 0.7409\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.90879\n",
      "Epoch 14/50\n",
      "750/750 [==============================] - 154s 205ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.9994 - val_accuracy: 0.7414\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.90879\n",
      "Epoch 15/50\n",
      "750/750 [==============================] - 154s 206ms/step - loss: 0.0036 - accuracy: 0.9999 - val_loss: 1.0200 - val_accuracy: 0.7359\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.90879\n",
      "Epoch 16/50\n",
      "750/750 [==============================] - 154s 205ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.0149 - val_accuracy: 0.7414\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.90879\n",
      "Epoch 17/50\n",
      "750/750 [==============================] - 154s 205ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.0221 - val_accuracy: 0.7428\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.90879\n",
      "Epoch 18/50\n",
      "750/750 [==============================] - 154s 205ms/step - loss: 0.0031 - accuracy: 0.9999 - val_loss: 1.0516 - val_accuracy: 0.7336\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.90879\n",
      "Epoch 19/50\n",
      "750/750 [==============================] - 169s 225ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.0587 - val_accuracy: 0.7329\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.90879\n",
      "Epoch 20/50\n",
      "750/750 [==============================] - 154s 206ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.0383 - val_accuracy: 0.7388\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.90879\n",
      "Epoch 21/50\n",
      "750/750 [==============================] - 154s 205ms/step - loss: 0.0036 - accuracy: 0.9998 - val_loss: 1.0354 - val_accuracy: 0.7385\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.90879\n",
      "Epoch 22/50\n",
      "750/750 [==============================] - 154s 206ms/step - loss: 0.0030 - accuracy: 0.9998 - val_loss: 1.0418 - val_accuracy: 0.7358\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.90879\n",
      "Epoch 23/50\n",
      "750/750 [==============================] - 154s 206ms/step - loss: 0.0024 - accuracy: 0.9999 - val_loss: 1.0556 - val_accuracy: 0.7375\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.90879\n",
      "Epoch 24/50\n",
      "750/750 [==============================] - 154s 205ms/step - loss: 0.0023 - accuracy: 0.9999 - val_loss: 1.0549 - val_accuracy: 0.7376\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.90879\n",
      "Epoch 25/50\n",
      "750/750 [==============================] - 154s 206ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.0551 - val_accuracy: 0.7390\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.90879\n",
      "Epoch 26/50\n",
      "750/750 [==============================] - 154s 205ms/step - loss: 0.0022 - accuracy: 0.9998 - val_loss: 1.0739 - val_accuracy: 0.7353\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.90879\n",
      "Epoch 27/50\n",
      "750/750 [==============================] - 154s 205ms/step - loss: 0.0024 - accuracy: 0.9999 - val_loss: 1.0641 - val_accuracy: 0.7374\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.90879\n",
      "Epoch 28/50\n",
      "750/750 [==============================] - 154s 206ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.0630 - val_accuracy: 0.7359\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.90879\n",
      "Epoch 29/50\n",
      "750/750 [==============================] - 169s 225ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.0714 - val_accuracy: 0.7365\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.90879\n",
      "Epoch 30/50\n",
      "750/750 [==============================] - 154s 206ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 1.0728 - val_accuracy: 0.7374\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.90879\n",
      "Epoch 31/50\n",
      "750/750 [==============================] - 154s 206ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.0727 - val_accuracy: 0.7365\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.90879\n",
      "Epoch 32/50\n",
      "750/750 [==============================] - 154s 205ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.0722 - val_accuracy: 0.7390\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.90879\n",
      "Epoch 33/50\n",
      "750/750 [==============================] - 154s 205ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.0844 - val_accuracy: 0.7337\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.90879\n",
      "Epoch 34/50\n",
      "750/750 [==============================] - 154s 205ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.0824 - val_accuracy: 0.7369\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.90879\n",
      "Epoch 35/50\n",
      "750/750 [==============================] - 154s 206ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 1.0890 - val_accuracy: 0.7371\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.90879\n",
      "Epoch 36/50\n",
      "750/750 [==============================] - 154s 206ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.0872 - val_accuracy: 0.7364\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.90879\n",
      "Epoch 37/50\n",
      "750/750 [==============================] - 154s 206ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.0915 - val_accuracy: 0.7367\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.90879\n",
      "Epoch 38/50\n",
      "750/750 [==============================] - 154s 206ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 1.1003 - val_accuracy: 0.7358\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.90879\n",
      "Epoch 39/50\n",
      "750/750 [==============================] - 155s 206ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.0903 - val_accuracy: 0.7375\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.90879\n",
      "Epoch 40/50\n",
      "750/750 [==============================] - 169s 226ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.0938 - val_accuracy: 0.7380\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.90879\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 155s 206ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.0956 - val_accuracy: 0.7385\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.90879\n",
      "Epoch 42/50\n",
      "750/750 [==============================] - 154s 206ms/step - loss: 9.7128e-04 - accuracy: 1.0000 - val_loss: 1.0980 - val_accuracy: 0.7382\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.90879\n",
      "Epoch 43/50\n",
      "750/750 [==============================] - 169s 226ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.0929 - val_accuracy: 0.7366\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.90879\n",
      "Epoch 44/50\n",
      "750/750 [==============================] - 155s 206ms/step - loss: 9.1652e-04 - accuracy: 1.0000 - val_loss: 1.0968 - val_accuracy: 0.7382\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.90879\n",
      "Epoch 45/50\n",
      "750/750 [==============================] - 154s 206ms/step - loss: 8.9653e-04 - accuracy: 1.0000 - val_loss: 1.1043 - val_accuracy: 0.7362\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.90879\n",
      "Epoch 46/50\n",
      "750/750 [==============================] - 154s 206ms/step - loss: 9.0483e-04 - accuracy: 1.0000 - val_loss: 1.1021 - val_accuracy: 0.7389\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.90879\n",
      "Epoch 47/50\n",
      "750/750 [==============================] - 155s 206ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 1.1963 - val_accuracy: 0.7111\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.90879\n",
      "Epoch 48/50\n",
      "750/750 [==============================] - 154s 206ms/step - loss: 0.0060 - accuracy: 0.9995 - val_loss: 1.1473 - val_accuracy: 0.7243\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.90879\n",
      "Epoch 49/50\n",
      "750/750 [==============================] - 154s 206ms/step - loss: 0.0036 - accuracy: 0.9997 - val_loss: 1.1137 - val_accuracy: 0.7324\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.90879\n",
      "Epoch 50/50\n",
      "750/750 [==============================] - 154s 206ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.1092 - val_accuracy: 0.7329\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.90879\n"
     ]
    }
   ],
   "source": [
    "mixup_model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "history_resnet50_mixup = mixup_model.fit(\n",
    "    ds_train_mixup,\n",
    "    steps_per_epoch=int(ds_info.splits['train'].num_examples/16),\n",
    "    validation_steps=int(ds_info.splits['test'].num_examples/16),\n",
    "    epochs=EPOCH,\n",
    "    validation_data=ds_test_all,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    "    callbacks=[checkpoint_mixup]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8345a613",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixup_model.save_weights(os.getenv('HOME')+'/aiffel/model_weight/resnet50_mixup_model_weight.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e67fb827",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixup_model.save(os.getenv('HOME')+'/aiffel/model_weight/resnet50_mixup_all_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a9ee3526",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('history/history_resnet50_mixup.json', 'w') as f:\n",
    "    pd.DataFrame(history_resnet50_mixup.history).to_json(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb1a6833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(history_resnet50_mixup.history['loss'], 'r')\n",
    "plt.plot(history_resnet50_mixup.history['val_loss'], 'b')\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(history_resnet50_mixup.history['accuracy'], 'r')\n",
    "plt.plot(history_resnet50_mixup.history['val_accuracy'], 'b')\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
